{
 "cells": [
  {
   "cell_type": "code",

   "execution_count": 1,

   "execution_count": 18,

   "id": "9b13e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence, TypedDict, List, Dict\n",
    "from dotenv import load_dotenv  \n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.prebuilt import ToolNode\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches, Pt\n",
    "from pptx.enum.text import MSO_ANCHOR\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 2,

   "execution_count": 19,

   "id": "5fb1692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 3,

   "execution_count": 20,

   "id": "2443f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    subtopic: List[str]\n",
    "    slide_segments: List[Dict[str, str]]\n",
    "    ppt_output_path: str\n",
    "    audio_output_path: List[str]"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 4,

   "execution_count": 21,

   "id": "cd09c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_to_agent_state(json_path: str) -> AgentState:\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    complete_slide_segments = []\n",
    "    for slide in data.get('slide_segments', []):\n",
    "        complete_slide = {\n",
    "            \"slide_no\": slide.get(\"slide_no\", 0),\n",
    "            \"subtopic\": slide.get(\"subtopic\", \"\"),\n",
    "            \"content_to_display\": slide.get(\"content_to_display\", \"\"),\n",
    "            \"narration_script\": slide.get(\"narration_script\", \"\"),\n",
    "            \"is_blank_slide\": slide.get(\"is_blank_slide\", False),\n",
    "            \"image_address\": slide.get(\"image_address\", \"\"),\n",
    "            \"video_address\": slide.get(\"video_address\", \"\"),\n",
    "            \"image_position\": slide.get(\"image_position\", \"\"),\n",
    "            \"content_position\": slide.get(\"test_position\", \"\")\n",
    "        }\n",
    "        complete_slide_segments.append(complete_slide)\n",
    "\n",
    "    return AgentState(\n",
    "        messages=[],\n",
    "        subtopic=data.get('subtopics', []),\n",
    "        slide_segments=complete_slide_segments,\n",
    "        ppt_output_path=\"\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 6,
   "id": "aa79531c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting TTS\n",
      "  Using cached tts-0.22.0-cp311-cp311-win_amd64.whl\n",
      "Requirement already satisfied: numpy>=1.24.3 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from TTS) (2.3.1)\n",
      "Collecting cython>=0.29.30 (from TTS)\n",
      "  Obtaining dependency information for cython>=0.29.30 from https://files.pythonhosted.org/packages/a2/50/0aa65be5a4ab65bde3224b8fd23ed795f699d1e724ac109bb0a32036b82d/cython-3.1.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached cython-3.1.2-cp311-cp311-win_amd64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: scipy>=1.11.2 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from TTS) (1.16.0)\n",
      "Requirement already satisfied: torch>=2.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from TTS) (2.7.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from TTS) (2.7.1)\n",
      "Collecting soundfile>=0.12.0 (from TTS)\n",
      "  Obtaining dependency information for soundfile>=0.12.0 from https://files.pythonhosted.org/packages/14/e9/6b761de83277f2f02ded7e7ea6f07828ec78e4b229b80e4ca55dd205b9dc/soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata\n",
      "  Using cached soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Collecting librosa>=0.10.0 (from TTS)\n",
      "  Obtaining dependency information for librosa>=0.10.0 from https://files.pythonhosted.org/packages/b5/ba/c63c5786dfee4c3417094c4b00966e61e4a63efecee22cb7b4c0387dda83/librosa-0.11.0-py3-none-any.whl.metadata\n",
      "  Using cached librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.3.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from TTS) (1.7.0)\n",
      "Requirement already satisfied: numba>=0.57.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from TTS) (0.57.0)\n",
      "Collecting inflect>=5.6.0 (from TTS)\n",
      "  Obtaining dependency information for inflect>=5.6.0 from https://files.pythonhosted.org/packages/8a/eb/427ed2b20a38a4ee29f24dbe4ae2dafab198674fe9a85e3d6adf9e5f5f41/inflect-7.5.0-py3-none-any.whl.metadata\n",
      "  Using cached inflect-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from TTS) (4.65.0)\n",
      "Collecting anyascii>=0.3.0 (from TTS)\n",
      "  Obtaining dependency information for anyascii>=0.3.0 from https://files.pythonhosted.org/packages/c2/76/783b75a21ce3563b8709050de030ae253853b147bd52e141edc1025aa268/anyascii-0.3.3-py3-none-any.whl.metadata\n",
      "  Using cached anyascii-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: pyyaml>=6.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from TTS) (6.0)\n",
      "Requirement already satisfied: fsspec>=2023.6.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from TTS) (2025.7.0)\n",
      "Requirement already satisfied: aiohttp>=3.8.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from TTS) (3.8.3)\n",
      "Requirement already satisfied: packaging>=23.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from TTS) (24.2)\n",
      "Requirement already satisfied: flask>=2.0.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from TTS) (2.2.2)\n",
      "Collecting pysbd>=0.3.4 (from TTS)\n",
      "  Obtaining dependency information for pysbd>=0.3.4 from https://files.pythonhosted.org/packages/48/0a/c99fb7d7e176f8b176ef19704a32e6a9c6aafdf19ef75a187f701fc15801/pysbd-0.3.4-py3-none-any.whl.metadata\n",
      "  Using cached pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting umap-learn>=0.5.1 (from TTS)\n",
      "  Obtaining dependency information for umap-learn>=0.5.1 from https://files.pythonhosted.org/packages/6b/b1/c24deeda9baf1fd491aaad941ed89e0fed6c583a117fd7b79e0a33a1e6c0/umap_learn-0.5.9.post2-py3-none-any.whl.metadata\n",
      "  Using cached umap_learn-0.5.9.post2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pandas<2.0,>=1.4 (from TTS)\n",
      "  Obtaining dependency information for pandas<2.0,>=1.4 from https://files.pythonhosted.org/packages/da/6d/1235da14daddaa6e47f74ba0c255358f0ce7a6ee05da8bf8eb49161aa6b5/pandas-1.5.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached pandas-1.5.3-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from TTS) (3.8.0)\n",
      "Collecting trainer>=0.0.32 (from TTS)\n",
      "  Obtaining dependency information for trainer>=0.0.32 from https://files.pythonhosted.org/packages/a0/38/c4381497fde987c72fc58d9b534dfd9e254e34d402e06be232f40e1baf66/trainer-0.0.36-py3-none-any.whl.metadata\n",
      "  Using cached trainer-0.0.36-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting coqpit>=0.0.16 (from TTS)\n",
      "  Obtaining dependency information for coqpit>=0.0.16 from https://files.pythonhosted.org/packages/a3/d8/3f922be74a0aa9ef54ae1f82723fb1882988dce7fa420ba6af24e52c1987/coqpit-0.0.17-py3-none-any.whl.metadata\n",
      "  Using cached coqpit-0.0.17-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jieba (from TTS)\n",
      "  Using cached jieba-0.42.1-py3-none-any.whl\n",
      "Collecting pypinyin (from TTS)\n",
      "  Obtaining dependency information for pypinyin from https://files.pythonhosted.org/packages/b6/ec/2c04ac863e7a85bb68b0b655cec2f19853d51d305ce3d785848db6037b8d/pypinyin-0.54.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached pypinyin-0.54.0-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting hangul_romanize (from TTS)\n",
      "  Obtaining dependency information for hangul_romanize from https://files.pythonhosted.org/packages/e9/12/c5d2efd69d634d33c1a0a90256116bdefd023b27ca477f1fc5c7620aa21f/hangul_romanize-0.1.0-py3-none-any.whl.metadata\n",
      "  Using cached hangul_romanize-0.1.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting gruut[de,es,fr]==2.2.3 (from TTS)\n",
      "  Using cached gruut-2.2.3-py3-none-any.whl\n",
      "Collecting jamo (from TTS)\n",
      "  Obtaining dependency information for jamo from https://files.pythonhosted.org/packages/ac/cc/49812faae67f9a24be6ddaf58a2cf7e8c3cbfcf5b762d9414f7103d2ea2c/jamo-0.4.1-py3-none-any.whl.metadata\n",
      "  Using cached jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: nltk in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from TTS) (3.8.1)\n",
      "Collecting g2pkk>=0.1.1 (from TTS)\n",
      "  Obtaining dependency information for g2pkk>=0.1.1 from https://files.pythonhosted.org/packages/25/9e/37665b4cf4e99dd4d294b178f79cd70fed2c5beff995e77132ceda97cfa1/g2pkk-0.1.2-py3-none-any.whl.metadata\n",
      "  Using cached g2pkk-0.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting bangla (from TTS)\n",
      "  Obtaining dependency information for bangla from https://files.pythonhosted.org/packages/e6/9f/73d69c27f2daf35c7d1ae0de6d8d97fa43f0507b1f25444111d313b7679b/bangla-0.0.5-py3-none-any.whl.metadata\n",
      "  Using cached bangla-0.0.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting bnnumerizer (from TTS)\n",
      "  Using cached bnnumerizer-0.0.2-py3-none-any.whl\n",
      "Collecting bnunicodenormalizer (from TTS)\n",
      "  Obtaining dependency information for bnunicodenormalizer from https://files.pythonhosted.org/packages/e9/37/df46a2375c462623ebf17258926cacb94e01a6159c93f9144a6b42bc33fe/bnunicodenormalizer-0.1.7-py3-none-any.whl.metadata\n",
      "  Using cached bnunicodenormalizer-0.1.7-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting einops>=0.6.0 (from TTS)\n",
      "  Obtaining dependency information for einops>=0.6.0 from https://files.pythonhosted.org/packages/87/62/9773de14fe6c45c23649e98b83231fffd7b9892b6cf863251dc2afa73643/einops-0.8.1-py3-none-any.whl.metadata\n",
      "  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: transformers>=4.33.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from TTS) (4.53.2)\n",
      "Collecting encodec>=0.1.1 (from TTS)\n",
      "  Using cached encodec-0.1.1-py3-none-any.whl\n",
      "Collecting unidecode>=1.3.2 (from TTS)\n",
      "  Obtaining dependency information for unidecode>=1.3.2 from https://files.pythonhosted.org/packages/8f/b7/559f59d57d18b44c6d1250d2eeaa676e028b9c527431f5d0736478a73ba1/Unidecode-1.4.0-py3-none-any.whl.metadata\n",
      "  Using cached Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting num2words (from TTS)\n",
      "  Obtaining dependency information for num2words from https://files.pythonhosted.org/packages/d6/5b/545e9267a1cc080c8a1be2746113a063e34bcdd0f5173fd665a5c13cb234/num2words-0.5.14-py3-none-any.whl.metadata\n",
      "  Using cached num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting spacy[ja]>=3 (from TTS)\n",
      "  Obtaining dependency information for spacy[ja]>=3 from https://files.pythonhosted.org/packages/92/e7/8176484801c67dcd814f141991fe0a3c9b5b4a3583ea30c2062e93d1aa6b/spacy-3.8.7-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached spacy-3.8.7-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.11.0)\n",
      "Collecting dateparser~=1.1.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Obtaining dependency information for dateparser~=1.1.0 from https://files.pythonhosted.org/packages/7a/bf/457ed5be028fb235f8f5ad40b5ddbf67023e0017090ea324d0fe6239a73c/dateparser-1.1.8-py2.py3-none-any.whl.metadata\n",
      "  Using cached dateparser-1.1.8-py2.py3-none-any.whl.metadata (27 kB)\n",
      "Collecting gruut-ipa<1.0,>=0.12.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Using cached gruut_ipa-0.13.0-py3-none-any.whl\n",
      "Collecting gruut-lang-en~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Using cached gruut_lang_en-2.0.1-py3-none-any.whl\n",
      "Collecting jsonlines~=1.2.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Obtaining dependency information for jsonlines~=1.2.0 from https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached jsonlines-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting networkx<3.0.0,>=2.5.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Obtaining dependency information for networkx<3.0.0,>=2.5.0 from https://files.pythonhosted.org/packages/42/31/d2f89f1ae42718f8c8a9e440ebe38d7d5fe1e0d9eb9178ce779e365b3ab0/networkx-2.8.8-py3-none-any.whl.metadata\n",
      "  Using cached networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting numpy>=1.24.3 (from TTS)\n",
      "  Obtaining dependency information for numpy>=1.24.3 from https://files.pythonhosted.org/packages/3f/6b/5610004206cf7f8e7ad91c5a85a8c71b2f2f8051a0c0c4d5916b76d6cbb2/numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Collecting python-crfsuite~=0.9.7 (from gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Obtaining dependency information for python-crfsuite~=0.9.7 from https://files.pythonhosted.org/packages/f3/4c/2aabe6f3c06a6e62fb4d80d0ed224e3d813b7fc5bc7d9aba52e724639268/python_crfsuite-0.9.11-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached python_crfsuite-0.9.11-cp311-cp311-win_amd64.whl.metadata (4.4 kB)\n",
      "Collecting gruut-lang-de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Using cached gruut_lang_de-2.0.1-py3-none-any.whl\n",
      "Collecting gruut-lang-es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Using cached gruut_lang_es-2.0.1-py3-none-any.whl\n",
      "Collecting gruut-lang-fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Using cached gruut_lang_fr-2.0.2-py3-none-any.whl\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from aiohttp>=3.8.1->TTS) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from aiohttp>=3.8.1->TTS) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from aiohttp>=3.8.1->TTS) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from aiohttp>=3.8.1->TTS) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from aiohttp>=3.8.1->TTS) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from aiohttp>=3.8.1->TTS) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from aiohttp>=3.8.1->TTS) (1.2.0)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from flask>=2.0.1->TTS) (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from flask>=2.0.1->TTS) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from flask>=2.0.1->TTS) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from flask>=2.0.1->TTS) (8.0.4)\n",
      "Requirement already satisfied: more_itertools>=8.5.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from inflect>=5.6.0->TTS) (8.12.0)\n",
      "Collecting typeguard>=4.0.1 (from inflect>=5.6.0->TTS)\n",
      "  Obtaining dependency information for typeguard>=4.0.1 from https://files.pythonhosted.org/packages/1b/a9/e3aee762739c1d7528da1c3e06d518503f8b6c439c35549b53735ba52ead/typeguard-4.4.4-py3-none-any.whl.metadata\n",
      "  Using cached typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa>=0.10.0->TTS)\n",
      "  Obtaining dependency information for audioread>=2.1.9 from https://files.pythonhosted.org/packages/57/8d/30aa32745af16af0a9a650115fbe81bde7c610ed5c21b381fca0196f3a7f/audioread-3.0.1-py3-none-any.whl.metadata\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from librosa>=0.10.0->TTS) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\nikhi\\appdata\\roaming\\python\\python311\\site-packages (from librosa>=0.10.0->TTS) (5.1.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from librosa>=0.10.0->TTS) (1.4.0)\n",
      "Collecting soxr>=0.3.2 (from librosa>=0.10.0->TTS)\n",
      "  Obtaining dependency information for soxr>=0.3.2 from https://files.pythonhosted.org/packages/86/94/6a7e91bea7e6ca193ee429869b8f18548cd79759e064021ecb5756024c7c/soxr-0.5.0.post1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached soxr-0.5.0.post1-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from librosa>=0.10.0->TTS) (4.14.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from librosa>=0.10.0->TTS) (0.2)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from librosa>=0.10.0->TTS) (1.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib>=3.7.0->TTS) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib>=3.7.0->TTS) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib>=3.7.0->TTS) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib>=3.7.0->TTS) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib>=3.7.0->TTS) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib>=3.7.0->TTS) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib>=3.7.0->TTS) (2.8.2)\n",
      "Collecting docopt>=0.6.2 (from num2words->TTS)\n",
      "  Using cached docopt-0.6.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from numba>=0.57.0->TTS) (0.40.0)\n",
      "Collecting numpy>=1.24.3 (from TTS)\n",
      "  Obtaining dependency information for numpy>=1.24.3 from https://files.pythonhosted.org/packages/d8/ec/ebef2f7d7c28503f958f0f8b992e7ce606fb74f9e891199329d5f5f87404/numpy-1.24.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached numpy-1.24.4-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from pandas<2.0,>=1.4->TTS) (2022.7)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from scikit-learn>=1.3.0->TTS) (3.6.0)\n",
      "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting scipy>=1.11.2 (from TTS)\n",
      "  Obtaining dependency information for scipy>=1.11.2 from https://files.pythonhosted.org/packages/ab/a7/0ddaf514ce8a8714f6ed243a2b391b41dbb65251affe21ee3077ec45ea9a/scipy-1.15.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached scipy-1.15.3-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from soundfile>=0.12.0->TTS) (1.15.1)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for spacy-legacy<3.1.0,>=3.0.11 from https://files.pythonhosted.org/packages/c3/55/12e842c70ff8828e34e543a2c7176dac4da006ca6901c9e8b43efab8bc6b/spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for spacy-loggers<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/33/78/d1a1a026ef3af911159398c939b1509d5c36fe524c7b644f34a5146c4e16/spacy_loggers-1.0.5-py3-none-any.whl.metadata\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for murmurhash<1.1.0,>=0.28.0 from https://files.pythonhosted.org/packages/79/17/f2a38558e150a0669d843f75e128afb83c1a67af41885ea2acb940e18e2a/murmurhash-1.0.13-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached murmurhash-1.0.13-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for cymem<2.1.0,>=2.0.2 from https://files.pythonhosted.org/packages/56/c8/75f75889401b20f4c3a7c5965dda09df42913e904ddc2ffe7ef3bdf25061/cymem-2.0.11-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached cymem-2.0.11-cp311-cp311-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for preshed<3.1.0,>=3.0.2 from https://files.pythonhosted.org/packages/3a/86/d8f32b0b31a36ee8770a9b1a95321430e364cd0ba4bfebb7348aed2f198d/preshed-3.0.10-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached preshed-3.0.10-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for thinc<8.4.0,>=8.3.4 from https://files.pythonhosted.org/packages/94/40/7e5e840ac2e835fbf5d87e3ab94df7d678d846aaf28b12d46538ed36bf7f/thinc-8.3.6-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached thinc-8.3.6-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for wasabi<1.2.0,>=0.9.1 from https://files.pythonhosted.org/packages/06/7c/34330a89da55610daa5f245ddce5aab81244321101614751e7537f125133/wasabi-1.1.3-py3-none-any.whl.metadata\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for srsly<3.0.0,>=2.4.3 from https://files.pythonhosted.org/packages/bb/da/657a685f63028dcb00ccdc4ac125ed347c8bff6fa0dab6a9eb3dc45f3223/srsly-2.5.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached srsly-2.5.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for catalogue<2.1.0,>=2.0.6 from https://files.pythonhosted.org/packages/9e/96/d32b941a501ab566a16358d68b6eb4e4acc373fab3c3c4d7d9e649f7b4bb/catalogue-2.0.10-py3-none-any.whl.metadata\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for weasel<0.5.0,>=0.1.0 from https://files.pythonhosted.org/packages/2a/87/abd57374044e1f627f0a905ac33c1a7daab35a3a815abfea4e1bafd3fdb1/weasel-0.4.1-py3-none-any.whl.metadata\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for typer<1.0.0,>=0.3.0 from https://files.pythonhosted.org/packages/76/42/3efaf858001d2c2913de7f354563e3a3a2f0decae3efe98427125a8f441e/typer-0.16.0-py3-none-any.whl.metadata\n",
      "  Using cached typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from spacy[ja]>=3->TTS) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from spacy[ja]>=3->TTS) (2.11.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from spacy[ja]>=3->TTS) (68.0.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for langcodes<4.0.0,>=3.2.0 from https://files.pythonhosted.org/packages/c3/6b/068c2ea7a712bf805c62445bd9e9c06d7340358ef2824150eceac027444b/langcodes-3.5.0-py3-none-any.whl.metadata\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting sudachipy!=0.6.1,>=0.5.2 (from spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for sudachipy!=0.6.1,>=0.5.2 from https://files.pythonhosted.org/packages/79/34/ace16ae26b067ae1a0d69e4294c18203f903739f73e6655c555be51a7884/SudachiPy-0.6.10-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached SudachiPy-0.6.10-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting sudachidict_core>=20211220 (from spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for sudachidict_core>=20211220 from https://files.pythonhosted.org/packages/39/df/83d0cf0d94e812519c8b556b6ad0b430d074e163eb917e161f90cce2d716/sudachidict_core-20250515-py3-none-any.whl.metadata\n",
      "  Using cached sudachidict_core-20250515-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from torch>=2.1->TTS) (3.13.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from torch>=2.1->TTS) (1.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from tqdm>=4.64.1->TTS) (0.4.6)\n",
      "Requirement already satisfied: psutil in c:\\users\\nikhi\\appdata\\roaming\\python\\python311\\site-packages (from trainer>=0.0.32->TTS) (6.1.1)\n",
      "Collecting tensorboard (from trainer>=0.0.32->TTS)\n",
      "  Obtaining dependency information for tensorboard from https://files.pythonhosted.org/packages/5d/12/4f70e8e2ba0dbe72ea978429d8530b0333f0ed2140cc571a48802878ef99/tensorboard-2.19.0-py3-none-any.whl.metadata\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from transformers>=4.33.0->TTS) (0.33.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from transformers>=4.33.0->TTS) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from transformers>=4.33.0->TTS) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from transformers>=4.33.0->TTS) (0.5.3)\n",
      "Collecting pynndescent>=0.5 (from umap-learn>=0.5.1->TTS)\n",
      "  Obtaining dependency information for pynndescent>=0.5 from https://files.pythonhosted.org/packages/d2/53/d23a97e0a2c690d40b165d1062e2c4ccc796be458a1ce59f6ba030434663/pynndescent-0.5.13-py3-none-any.whl.metadata\n",
      "  Using cached pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.0->TTS) (2.21)\n",
      "Collecting tzlocal (from dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Obtaining dependency information for tzlocal from https://files.pythonhosted.org/packages/c2/14/e2a54fabd4f08cd7af1c07030603c3356b74da07f7cc056e600436edfa17/tzlocal-5.3.1-py3-none-any.whl.metadata\n",
      "  Using cached tzlocal-5.3.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from Jinja2>=3.0->flask>=2.0.1->TTS) (2.1.1)\n",
      "Requirement already satisfied: six in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from jsonlines~=1.2.0->gruut[de,es,fr]==2.2.3->TTS) (1.16.0)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for language-data>=1.2 from https://files.pythonhosted.org/packages/5d/e9/5a5ffd9b286db82be70d677d0a91e4d58f7912bb8dd026ddeeb4abe70679/language_data-1.3.0-py3-none-any.whl.metadata\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: appdirs in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa>=0.10.0->TTS) (1.4.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy[ja]>=3->TTS) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy[ja]>=3->TTS) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy[ja]>=3->TTS) (0.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy[ja]>=3->TTS) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy[ja]>=3->TTS) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy[ja]>=3->TTS) (2023.7.22)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=2.1->TTS) (1.3.0)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for blis<1.4.0,>=1.3.0 from https://files.pythonhosted.org/packages/35/3a/f9414cf9b2c43aad87e8687ad2cdb0e66e996c20288584621a12725e83dd/blis-1.3.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached blis-1.3.0-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for confection<1.0.0,>=0.0.1 from https://files.pythonhosted.org/packages/0c/00/3106b1854b45bd0474ced037dfe6b73b90fe68a68968cef47c23de3d43d2/confection-0.1.5-py3-none-any.whl.metadata\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for thinc<8.4.0,>=8.3.4 from https://files.pythonhosted.org/packages/d9/98/f910b8d8113ab9b955a68e9bbf0d5bd0e828f22dd6d3c226af6ec3970817/thinc-8.3.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached thinc-8.3.4-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for blis<1.3.0,>=1.2.0 from https://files.pythonhosted.org/packages/7c/c0/047fef3ac4a531903c52ba7c108fd608556627723bfef7554f040b10e556/blis-1.2.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached blis-1.2.1-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for shellingham>=1.3.0 from https://files.pythonhosted.org/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl.metadata\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for rich>=10.11.0 from https://files.pythonhosted.org/packages/0d/9b/63f4c7ebc259242c89b3acafdb37b41d1185c07ff0011164674e9076b491/rich-14.0.0-py3-none-any.whl.metadata\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for cloudpathlib<1.0.0,>=0.7.0 from https://files.pythonhosted.org/packages/40/e7/6fea57b887f8e367c1e4a496ba03bfaf57824b766f777723ce1faf28834b/cloudpathlib-0.21.1-py3-none-any.whl.metadata\n",
      "  Using cached cloudpathlib-0.21.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy[ja]>=3->TTS) (5.2.1)\n",
      "Collecting absl-py>=0.4 (from tensorboard->trainer>=0.0.32->TTS)\n",
      "  Obtaining dependency information for absl-py>=0.4 from https://files.pythonhosted.org/packages/8f/aa/ba0014cc4659328dc818a28827be78e6d97312ab0cb98105a770924dc11e/absl_py-2.3.1-py3-none-any.whl.metadata\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard->trainer>=0.0.32->TTS)\n",
      "  Obtaining dependency information for grpcio>=1.48.2 from https://files.pythonhosted.org/packages/af/66/e1bbb0c95ea222947f0829b3db7692c59b59bcc531df84442e413fa983d9/grpcio-1.73.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached grpcio-1.73.1-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from tensorboard->trainer>=0.0.32->TTS) (3.4.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from tensorboard->trainer>=0.0.32->TTS) (4.21.12)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->trainer>=0.0.32->TTS)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/7a/13/e503968fefabd4c6b2650af21e110aa8466fe21432cd7c43a84577a89438/tensorboard_data_server-0.7.2-py3-none-any.whl.metadata\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy[ja]>=3->TTS)\n",
      "  Obtaining dependency information for marisa-trie>=1.1.0 from https://files.pythonhosted.org/packages/fc/98/574b4e143e0a2f5f71af8716b6c4a8a46220f75a6e0847ce7d11ee0ba4aa/marisa_trie-1.2.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached marisa_trie-1.2.1-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy[ja]>=3->TTS) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy[ja]>=3->TTS) (2.15.1)\n",
      "Requirement already satisfied: tzdata in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from tzlocal->dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->TTS) (2023.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy[ja]>=3->TTS) (0.1.0)\n",
      "Using cached anyascii-0.3.3-py3-none-any.whl (345 kB)\n",
      "Using cached coqpit-0.0.17-py3-none-any.whl (13 kB)\n",
      "Using cached cython-3.1.2-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "Using cached einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Using cached g2pkk-0.1.2-py3-none-any.whl (25 kB)\n",
      "Using cached inflect-7.5.0-py3-none-any.whl (35 kB)\n",
      "Using cached librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Using cached num2words-0.5.14-py3-none-any.whl (163 kB)\n",
      "Using cached numpy-1.24.4-cp311-cp311-win_amd64.whl (14.8 MB)\n",
      "Using cached pandas-1.5.3-cp311-cp311-win_amd64.whl (10.3 MB)\n",
      "Using cached pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "Using cached scipy-1.15.3-cp311-cp311-win_amd64.whl (41.2 MB)\n",
      "Using cached soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "Using cached trainer-0.0.36-py3-none-any.whl (51 kB)\n",
      "Using cached umap_learn-0.5.9.post2-py3-none-any.whl (90 kB)\n",
      "Using cached Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
      "Using cached bangla-0.0.5-py3-none-any.whl (5.1 kB)\n",
      "Using cached bnunicodenormalizer-0.1.7-py3-none-any.whl (23 kB)\n",
      "Using cached hangul_romanize-0.1.0-py3-none-any.whl (4.6 kB)\n",
      "Using cached jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
      "Using cached pypinyin-0.54.0-py2.py3-none-any.whl (837 kB)\n",
      "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Using cached cymem-2.0.11-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Using cached dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
      "Using cached jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Using cached murmurhash-1.0.13-cp311-cp311-win_amd64.whl (24 kB)\n",
      "Using cached networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
      "Using cached preshed-3.0.10-cp311-cp311-win_amd64.whl (117 kB)\n",
      "Using cached pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "Using cached python_crfsuite-0.9.11-cp311-cp311-win_amd64.whl (301 kB)\n",
      "Using cached soxr-0.5.0.post1-cp311-cp311-win_amd64.whl (166 kB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Using cached srsly-2.5.1-cp311-cp311-win_amd64.whl (632 kB)\n",
      "Using cached sudachidict_core-20250515-py3-none-any.whl (72.1 MB)\n",
      "Using cached SudachiPy-0.6.10-cp311-cp311-win_amd64.whl (1.4 MB)\n",
      "Using cached thinc-8.3.4-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "Using cached typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "Using cached typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached spacy-3.8.7-cp311-cp311-win_amd64.whl (14.9 MB)\n",
      "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached blis-1.2.1-cp311-cp311-win_amd64.whl (6.2 MB)\n",
      "Using cached cloudpathlib-0.21.1-py3-none-any.whl (52 kB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached grpcio-1.73.1-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached tzlocal-5.3.1-py3-none-any.whl (18 kB)\n",
      "Using cached marisa_trie-1.2.1-cp311-cp311-win_amd64.whl (152 kB)\n",
      "Installing collected packages: sudachipy, jieba, jamo, hangul_romanize, gruut-lang-fr, gruut-lang-es, gruut-lang-en, gruut-lang-de, docopt, cymem, bnunicodenormalizer, bnnumerizer, bangla, wasabi, unidecode, tzlocal, typeguard, tensorboard-data-server, sudachidict_core, spacy-loggers, spacy-legacy, shellingham, python-crfsuite, pysbd, pypinyin, numpy, num2words, networkx, murmurhash, marisa-trie, jsonlines, gruut-ipa, grpcio, einops, cython, coqpit, cloudpathlib, catalogue, audioread, anyascii, absl-py, tensorboard, srsly, soxr, soundfile, scipy, rich, preshed, pandas, language-data, inflect, dateparser, blis, typer, trainer, langcodes, gruut, g2pkk, confection, weasel, thinc, pynndescent, librosa, encodec, umap-learn, spacy, TTS\n",
      "  Attempting uninstall: unidecode\n",
      "    Found existing installation: Unidecode 1.2.0\n",
      "    Uninstalling Unidecode-1.2.0:\n",
      "      Successfully uninstalled Unidecode-1.2.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.3.1\n",
      "    Uninstalling numpy-2.3.1:\n",
      "      Successfully uninstalled numpy-2.3.1\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.1\n",
      "    Uninstalling networkx-3.1:\n",
      "      Successfully uninstalled networkx-3.1\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.16.0\n",
      "    Uninstalling scipy-1.16.0:\n",
      "      Successfully uninstalled scipy-1.16.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.3.1\n",
      "    Uninstalling pandas-2.3.1:\n",
      "      Successfully uninstalled pandas-2.3.1\n",
      "Successfully installed TTS-0.22.0 absl-py-2.3.1 anyascii-0.3.3 audioread-3.0.1 bangla-0.0.5 blis-1.2.1 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.7 catalogue-2.0.10 cloudpathlib-0.21.1 confection-0.1.5 coqpit-0.0.17 cymem-2.0.11 cython-3.1.2 dateparser-1.1.8 docopt-0.6.2 einops-0.8.1 encodec-0.1.1 g2pkk-0.1.2 grpcio-1.73.1 gruut-2.2.3 gruut-ipa-0.13.0 gruut-lang-de-2.0.1 gruut-lang-en-2.0.1 gruut-lang-es-2.0.1 gruut-lang-fr-2.0.2 hangul_romanize-0.1.0 inflect-7.5.0 jamo-0.4.1 jieba-0.42.1 jsonlines-1.2.0 langcodes-3.5.0 language-data-1.3.0 librosa-0.11.0 marisa-trie-1.2.1 murmurhash-1.0.13 networkx-2.8.8 num2words-0.5.14 numpy-1.24.4 pandas-1.5.3 preshed-3.0.10 pynndescent-0.5.13 pypinyin-0.54.0 pysbd-0.3.4 python-crfsuite-0.9.11 rich-14.0.0 scipy-1.15.3 shellingham-1.5.4 soundfile-0.13.1 soxr-0.5.0.post1 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 sudachidict_core-20250515 sudachipy-0.6.10 tensorboard-2.19.0 tensorboard-data-server-0.7.2 thinc-8.3.4 trainer-0.0.36 typeguard-4.4.4 typer-0.16.0 tzlocal-5.3.1 umap-learn-0.5.9.post2 unidecode-1.4.0 wasabi-1.1.3 weasel-0.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "langchain-community 0.3.27 requires numpy>=1.26.2; python_version < \"3.13\", but you have numpy 1.24.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40148603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nikhi\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Downloading model to C:\\Users\\Nikhi\\AppData\\Local\\tts\\tts_models--en--ljspeech--tacotron2-DDC\n",
      " > Model's license - apache 2.0\n",
      " > Check https://choosealicense.com/licenses/apache-2.0/ for more info.\n",
      " > Downloading model to C:\\Users\\Nikhi\\AppData\\Local\\tts\\vocoder_models--en--ljspeech--hifigan_v2\n",
      " > Model's license - apache 2.0\n",
      " > Check https://choosealicense.com/licenses/apache-2.0/ for more info.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from TTS.api import TTS\n",
    "\n",
    "\n",
    "# Load the free TTS model (offline)\n",
    "# tts = TTS(model_name=\"tts_models/en/ljspeech/tacotron2-DDC\", progress_bar=False, gpu=False)\n"
   ]
  },
  {
   "cell_type": "code",


   "execution_count": null,
   "id": "0cb5b041",
   "metadata": {},
   "outputs": [],
   "source": [

    "def narration_to_audio(state: dict) -> dict:\n",

    "from groq import Groq\n",
    "\n",
    "# Initialize the Groq client\n",
    "groq_client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "def narration_to_audio(state: AgentState) -> AgentState:\n",

    "    updated_audio_paths = []\n",
    "    output_dir = \"../assets/audio\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for slide in state['slide_segments']:\n",
    "        slide_no = slide[\"slide_no\"]\n",

    "        narration = slide.get(\"narration_script\", \"\")\n",

    "        narration = slide[\"narration_script\"]\n",

    "\n",
    "        if not narration:\n",
    "            updated_audio_paths.append(\"\")\n",
    "            continue\n",
    "\n",

    "        speech_file_path = os.path.join(output_dir, f\"Slide{slide_no}.wav\")\n",
    "\n",
    "        try:\n",
    "            # Generate audio using local model\n",
    "            tts.tts_to_file(text=narration, file_path=speech_file_path)\n",

    "        speech_file_path = os.path.join(output_dir, f\"slide{slide_no}.wav\")\n",
    "        \n",
    "        try:\n",
    "            response = groq_client.audio.speech.create(\n",
    "                model=\"playai-tts\",\n",
    "                voice=\"Fritz-PlayAI\", \n",
    "                input=narration,\n",
    "                response_format=\"wav\"\n",
    "            )\n",
    "            response.write_to_file(speech_file_path)\n",

    "            updated_audio_paths.append(speech_file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to generate audio for slide {slide_no}: {e}\")\n",
    "            updated_audio_paths.append(\"\")\n",
    "\n",
    "    state[\"audio_output_path\"] = updated_audio_paths\n",

    "    return state"

    "    return state\n"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": 9,

   "execution_count": 28,

   "id": "5826e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_node(state: AgentState) -> AgentState:\n",
    "    return load_json_to_agent_state('../assets/scripts/slide_segments.json')"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 10,

   "execution_count": 29,

   "id": "28ac912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"LoadData\", load_data_node)\n",
    "graph.add_node(\"NarrationToAudio\", narration_to_audio)\n",
    "\n",
    "graph.add_edge(START, \"LoadData\")\n",
    "graph.add_edge(\"LoadData\", \"NarrationToAudio\")\n",
    "graph.add_edge(\"NarrationToAudio\", END)\n",
    "\n",
    "\n",
    "compiled_graph = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 11,

   "execution_count": 30,

   "id": "d635e72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [

      " > Text splitted to sentences.\n",
      "[\"Welcome to our channel, where we'll be sharing tips and strategies on how to create profitable digital products.\", \"Today, we're going to talk about one of the most critical steps in this process: choosing a niche or topic.\", \"When you're looking to create a niche for your digital products, finding a profitable niche is one of the most important steps to reaching your goals.\", 'Having one specific niche is extremely important, and it can make the difference between success and failure for your niche products.', 'So, why is choosing a niche so crucial?', \"Well, what might work for one person probably won't for another.\", \"We want to tailor this niche to what you personally will be happy with, rather than just following what's making the most money right now.\", 'This is where the importance of choosing a niche comes in.', 'According to the facts, choosing a niche is a crucial step in creating profitable digital products.', \"It's a step that can make or break your success in the digital market.\", 'To start, we need to make a list of all the topics that we have intimate knowledge of.', 'This can be related to our past work experience, life experience, or even topics from the area around where we live.', \"Don't worry if you're not an expert in a certain subject  if there's a niche market that you're somewhat familiar with, you can still include it in your list.\", 'Having a specific niche is not just about being an expert, but also about being aware of the market.', 'Having a niche that is essential for success, as stated in fact 2, helps differentiate your products from others.', 'This means that having a niche that stands out can give you an edge over your competitors.', \"For example, let's say you're interested in health and fitness.\", \"You've worked out a lot, you've read books on the subject, and you've even tried different diets.\", 'These are all topics that you can draw from when creating your niche.', \"Now, let's look at facts 3 and 4, which state that to choose a profitable niche, you need to consider both forethought and research, including identifying problems people are experiencing and determining whether you can solve them, and researching your competition and analyzing their strengths and weaknesses is also vital in choosing a niche.\", 'This means that you need to not only know your niche but also understand the problems people are facing in that niche and how you can solve them.', \"Researching your competition is also crucial as it can give you insights on what works and what doesn't.\"]\n",
      "don't worry if you're not an expert in a certain subject  if there's a niche market that you're somewhat familiar with, you can still include it in your list.\n",
      " [!] Character '' not found in the vocabulary. Discarding it.\n",
      " > Processing time: 200.868723154068\n",
      " > Real-time factor: 1.0557110188498706\n",
      " > Text splitted to sentences.\n",
      "['Next, we need to identify problems that people are experiencing in this niche.', 'To do this, we can have one-on-one conversations or idea-extraction sessions with our target market.', 'We can also peruse forums, search Quora, or find forums related to our niche and take a look at the discussions that are taking place.', 'What questions are people asking?', 'What problems do they have?', \"Researching keywords using Google Trends and Google Adwords' Keyword Planner can also help us uncover popular search terms related to pain points.\", \"In this step, we're trying to identify the problems people are facing in our niche.\", 'This is where fact 5 comes in.', 'A niche with low-quality content or a lack of competition can be an opportunity for success.', \"This means that if there's a niche that has low-quality content or not enough competition, you can capitalize on it and create high-quality content that stands out in the market.\", \"But here's the thing: the presence of competition isn't necessarily a bad thing.\", \"It may actually be showing us that we've found a profitable niche.\", \"So, we need to do a thorough analysis of our competition and figure out whether there's still an opportunity to stand out in the crowd.\", 'Can we still rank for our keywords?', 'Is there a way to differentiate ourselves and create a unique product?', \"If the answer is yes, then we're onto something.\", 'Finally, we need to determine the profitability of our niche.', \"We should browse top products in our category and see how much money they're making.\", \"If we can't find any products, that's not a good sign.\", 'It might mean that nobody has been able to monetize the niche.', \"But if our search does turn up a decent number of products  not an overabundance of products  then we're in luck.\", 'We can make note of price points so that we can price our own products competitively.']\n",
      " > Processing time: 114.51395058631897\n",
      " > Real-time factor: 0.8371324656094953\n",
      " > Text splitted to sentences.\n",
      "['Hello and welcome to this tutorial on setting up a YouTube account.', \"If you're new to YouTube, creating an account is a straightforward process that can be done in just a few minutes.\", \"In this video, we'll show you how to create a YouTube account on both desktop and mobile devices.\", \"First, let's start with the desktop version.\", 'To create a YouTube account, you\\'ll need to visit the YouTube website at https://www.youtube.com and click on the \"Sign in\" button, then select \"Create account\".', 'This is a crucial step, as it will take you to a page where you can enter your personal details, such as your name, date of birth, and gender, as well as create a unique Gmail address.', 'If you already have a Google account, you can automatically create a YouTube account by logging in with your Google credentials.', \"This can save you some time and make the process even easier, as you won't have to fill out the sign-up form.\", \"However, keep in mind that you'll still need to agree to Google's terms of service to create a YouTube account.\", \"It's also worth noting that there's an age restriction for creating a YouTube account.\", \"Children must be at least 13 years old to create an account, so if you're creating an account for a child, make sure they meet this requirement.\"]\n",
      "to create a youtube account, you'll need to visit the youtube website at https,//www.youtube.com and click on the sign in button, then select create account.\n",
      " [!] Character '/' not found in the vocabulary. Discarding it.\n",
      " > Processing time: 79.67921113967896\n",
      " > Real-time factor: 0.821356058761398\n",
      " > Text splitted to sentences.\n",
      "[\"Now, let's talk about creating a YouTube account on mobile devices.\", \"To start, you'll need to open the YouTube app and tap the profile icon in the bottom-right corner of the screen.\", 'From there, select \"Add account\" and follow the prompts to create a new account.', 'One of the most important steps in creating a YouTube account is choosing a strong password.', \"It's recommended to use a mix of letters, numbers, and symbols to prevent hackers from accessing your account.\", 'A strong password will help keep your account secure, and prevent any unauthorized access.', 'In addition to your password, you may also be asked to enter a recovery email and phone number.', 'This is optional, but it can help you recover your account if you forget your password or need to verify your identity.', 'By entering this information, you can ensure that you can easily recover your account if needed.', \"Once you've completed these steps, you'll be taken to a page where you can review your account information.\", 'Make sure everything is correct, then tap the \"I agree\" button to accept Google\\'s terms of service.', \"That's it!\", 'Your YouTube account is now set up and ready to use.']\n",
      " > Processing time: 63.10895776748657\n",
      " > Real-time factor: 0.7563508894182699\n",
      " > Text splitted to sentences.\n",
      "['Hey everyone, welcome back to our channel.', \"Today we're going to talk about creating high-quality content, a crucial aspect of any digital marketing strategy.\", 'But what exactly is high-quality content?', \"Well, it's not just about throwing a bunch of words on a page.\", 'High-quality content is about creating content that achieves its marketing goals.', \"Whether you're trying to generate leads, increase brand awareness, or improve click-through rates, your content needs to be tailored to your specific goals.\", 'This is what sets high-quality content apart from just any ordinary content.', \"When you create high-quality content, you're not just randomly writing about a topic; you're intentionally crafting it to meet the needs of your target audience and drive real results for your business.\", \"High-quality content is not just about throwing words on a page; it's about creating content that provides value to your audience.\", 'So, what makes high-quality content tick?', \"It's all about being comprehensive, useful, helpful, educational, and accurate.\", \"Your content should provide value to your audience, whether it's answering their questions, solving their problems, or simply entertaining them.\", \"For instance, if you're creating a blog post about the benefits of a new product, you want to make sure that you're not just listing off features, but actually showing your audience how those features will benefit them in real life.\", 'You need to make sure that your content is well-researched, up-to-date, and trustworthy.', 'This is where key characteristics of high-quality content come in.', 'By being comprehensive, useful, helpful, educational, and accurate, you can create content that resonates with your audience and drives real results.']\n",
      " > Processing time: 102.19565558433533\n",
      " > Real-time factor: 0.7888161341303103\n",
      " > Text splitted to sentences.\n",
      "['But how do you measure the success of your content?', 'This is where key performance indicators, or KPIs, come in.', 'Are you ranking in the top three of Google for your target keywords?', 'Are you increasing brand awareness and customer loyalty?', 'Are you generating leads and sales?', 'These are just a few examples of KPIs that can help you determine the effectiveness of your content.', 'Understanding search intent is also crucial in creating high-quality content.', 'Search intent is the reason behind someone seeking out information online.', 'They may be searching for general information, looking for an answer to a question, seeking a solution for a problem, or browsing for a product to buy.', 'Before you start creating content, you need to understand how people will be finding and using it, as well as what outcome you want to see.', \"For example, if you're trying to sell a product or service, you need to create content that aligns with your marketing goals and user intent.\", 'This means understanding the needs of your audience and creating content that meets those needs.', \"You can't just create content that pushes your own agenda, but rather content that provides real value to your audience.\", \"Finally, let's talk about formatting.\", 'You want your content to be easily read, not just for your consumers but also for search engines.', 'Proper formatting, such as headings and subheadings, lists, and small blocks of text broken up by white space, can make a big difference in the overall performance of your content.', 'By following these best practices, you can create high-quality content that resonates with your audience and drives real results for your business.']\n",
      " > Processing time: 95.76588702201843\n",
      " > Real-time factor: 0.8105871196018791\n",
      " > Text splitted to sentences.\n",
      "['Hey everyone, welcome back to our channel.', \"Today we're going to talk about optimizing video titles and tags.\", 'As creators, we all want our content to reach a wider audience and drive more traffic to our websites.', 'But with so much competition on YouTube, it can be tough to stand out.', \"First, let's talk about video titles.\", \"Your title is the first thing viewers see when they come across your video, so it's got to be compelling, concise, and accurately represent the content of your video.\", \"Now, I know what you're thinking.\", '\"Do I really need to include keywords in my title?\"', 'The answer is yes.', 'Including relevant keywords early in your title can improve its visibility in search results.', 'This is because when viewers search for specific keywords, your video will appear in the search results if it has those keywords in the title.', 'For example, if you have a video about a vegan chocolate cake recipe, a title like \"Decadent Vegan Chocolate Cake Recipe | Easy & Eggless\" is more effective than a generic title like \"Vegan Chocolate Cake Recipe\".', \"It's got the keywords, it's concise, and it's accurately represents the content of your video.\", 'This way, when someone searches for \"vegan chocolate cake recipe\", your video is more likely to appear in the search results.', \"Next, let's talk about video descriptions.\", 'Your description should be comprehensive, include timestamps, links and CTAs, and relevant hashtags.', 'Think of it as an extension of your title.', 'You want to give viewers a clear idea of what they can expect from your video, and entice them to watch until the end.', \"This includes including timestamps in the description, so viewers can navigate directly to the section they're interested in.\", \"For instance, if you're creating a fitness video, your description could include workout details, nutrition tips, and links to related blog posts.\", \"Now, let's move on to tags.\", 'Tags are like keywords on steroids.', 'They help your video get discovered by users who are searching for content similar to yours.', 'So, how do you choose the right tags?', 'First, think about what users might search for when looking for content similar to yours.', 'Then, use a mix of broad and long-tail keywords.', 'Broad tags like \"fitness\" and \"cooking\" cast a wide net, while long-tail tags like \"HIIT workouts for beginners\" and \"vegan dessert recipes\" target specific niches.']\n",
      "for example, if you have a video about a vegan chocolate cake recipe, a title like decadent vegan chocolate cake recipe | easy and eggless is more effective than a generic title like vegan chocolate cake recipe.\n",
      " [!] Character '|' not found in the vocabulary. Discarding it.\n",
      " > Processing time: 151.71628403663635\n",
      " > Real-time factor: 0.8531707816147808\n",
      " > Text splitted to sentences.\n",
      "[\"And don't forget to do some research.\", \"Look at the tags used by successful channels in your niche, but don't copy them directly.\", 'Adapt relevant ones that fit your content.', 'Consistency is also key.', \"Use consistent tags across related videos to strengthen your channel's thematic relevance.\", 'This means that if you have multiple videos on a similar topic, use the same tags across all of them.', \"This will help viewers find all your related content in one place, and it will also help YouTube's algorithm understand what your channel is about.\", \"Finally, remember that optimization isn't a one-time task.\", 'You need to regularly review and refine your titles, descriptions, and tags based on performance metrics and audience feedback.', \"This means that you should be constantly monitoring your video's performance, such as views, engagement, and audience retention.\", 'And you should also be paying attention to what your audience is telling you through comments and feedback.', \"By mastering these elements, you'll enhance your YouTube channel's visibility and engagement, ultimately driving business growth.\", \"Thanks for watching, and I'll see you in the next video.\"]\n",
      " > Processing time: 66.32028126716614\n",
      " > Real-time factor: 0.7870625414106638\n",
      " > Text splitted to sentences.\n",
      "['Welcome to our video on building an audience and engagement.', 'As business owners and marketers, we know how crucial it is to have an engaged audience.', \"In this video, we'll explore five essential strategies for boosting and tracking audience engagement.\", \"First, let's talk about the importance of having an engaged audience.\", \"An engaged audience is critical to any brand's marketing success.\", 'This means that your audience is actively participating in your content, sharing it with others, and providing feedback.', \"When you have an engaged audience, it's easier to build a loyal following and achieve your marketing goals.\", 'One way to achieve an engaged audience is by getting to know them.', 'Experts recommend surveying your audience to understand their needs, preferences, and pain points.', 'This will help you create content that resonates with them and addresses their concerns.', 'By understanding your audience, you can tailor your content to meet their needs and build trust with them.', 'For example, a company that manufactures baby wipes may have thought they were only appealing to parents, but in reality, they also have a large following among people who use the wipes to remove makeup.', 'This highlights the importance of surveying your audience and not making assumptions about who they are or what they want.', 'Chevon Drew, Senior Communications Manager at Race Forward and Colorlines, highlights the importance of surveying your audience.', '\"Sometimes your current audience is different from the group you originally wanted to communicate with,\" he says.', '\"It\\'s essential to do less assuming and more surveying.\"', 'By surveying your audience, you can gain valuable insights into their needs and preferences, and create content that resonates with them.']\n",
      " > Processing time: 108.62691354751587\n",
      " > Real-time factor: 0.8959384832793919\n",
      " > Text splitted to sentences.\n",
      "[\"Now, let's talk about how to use engagement to achieve company goals.\", 'Your marketing and communication departments may be separate, but they should always meet to discuss revenue generation.', \"Elizabeth Riley Boyer, former Vice President of Marketing and Communications at Literacy Courseware Company ThinkCerca, emphasizes the importance of aligning your audience engagement initiatives with your company's overall goals.\", 'She recommends following the OKR framework, which stands for Objectives and Key Results.', '\"For nearly all businesses, you probably have some sort of revenue metric that you\\'re tracking,\" she says.', '\"At ThinkCerca, we have some great data on platform usage leading to great student achievement results, which leads to increased customer renewals and expansions.\"', \"By aligning your engagement strategy with your company's goals, you can create a more cohesive and effective marketing plan.\", 'And, as Tony Tran, Media Marketing Guru, puts it, \"What works for Wendy\\'s is entirely different from what works for Nike.\"', \"In addition to aligning your engagement strategy with your company goals, it's also essential to use the right tools to connect with your target audience.\", \"Using tools like journey maps, customer surveys, and marketing automation software can help you understand your audience's needs, preferences, and pain points.\", 'This will enable you to create content that resonates with them and addresses their concerns.', 'To track your audience engagement, you can use metrics such as page views, email opens, and Twitter interactions.', \"These metrics will give you a clear understanding of how well your content is performing and whether you're engaging with your audience effectively.\", 'Ultimately, businesses should align their engagement strategy with their company goals and image.', 'This will enable you to create a more cohesive and effective marketing plan that resonates with your audience and drives revenue growth.']\n",
      " > Processing time: 117.57283878326416\n",
      " > Real-time factor: 0.8609141447883761\n",
      " > Text splitted to sentences.\n",
      "['Hello everyone, welcome back to our channel.', \"Today, we're going to explore six ways to monetize your YouTube channel without making videos yourself.\", 'Yes, you read that right - you can earn money on YouTube without creating any content.', 'How cool is that?', \"To start, let's talk about one of the primary methods: joining the YouTube Partner Program.\", 'However, to be eligible, you need to meet the milestones of 1,000 subscribers and 4,000 hours of watch time.', \"This may seem daunting, but trust me, it's worth it.\", \"Once you've reached these milestones, you can start monetizing your channel through various strategies.\"]\n",
      " > Processing time: 40.561087131500244\n",
      " > Real-time factor: 0.8493109305199157\n",
      " > Text splitted to sentences.\n",
      "[\"Now, let's talk about digital products.\", 'Digital products, such as online courses, ebooks, and software, present an excellent opportunity for monetization.', 'While creating your own digital products can be time-consuming and costly, you can partner with creators who already offer courses or software and earn a commission for every sale.', 'One effective way to promote digital products is through affiliate marketing.', \"But, before we dive into that, let's discuss the importance of choosing the right niche.\", 'A successful niche should be evergreen, meaning it has sustained interest over time.', 'It should also have high demand and interest, as well as high CPM potential, making it attractive to advertisers.', 'With the right niche, you can effectively promote digital products through affiliate marketing using platforms like ClickBank and Digistore24.']\n",
      " > Processing time: 54.501583099365234\n",
      " > Real-time factor: 0.8531348728851966\n",
      " > Text splitted to sentences.\n",
      "['Hey everyone, welcome back to my channel.', \"Today, we're going to talk about something really important for any YouTuber: promoting your YouTube channel.\", 'Now, you might be thinking, \"Wait, I\\'ve already uploaded my videos, so I\\'m done, right?\"', 'Well, not quite.', 'Promoting your channel is an ongoing process that requires effort and strategy.', \"First, let's talk about why promoting your channel is so important.\", \"When you promote your channel, you're not just promoting your individual videos, you're building a community around your brand.\", \"And that's what's going to keep viewers engaged and coming back for more.\", 'This community can be built on various social media platforms, such as Instagram, Facebook, TikTok, Pinterest, and Twitter, as mentioned in fact 1.', 'By promoting your channel on these platforms, you can increase your reach and attract more viewers.', 'Another key aspect of promoting your channel is optimizing your content with search-friendly keywords.', 'As mentioned in fact 2, this can help your videos show up in YouTube search results and on Google.', \"Think about it this way: when you search for something on YouTube or Google, you're looking for specific information or content.\", \"If your video is optimized with the right keywords, it's more likely to show up in those search results and be seen by your target audience.\", 'To find these keywords, you can use tools like the Google Ads Keyword Planner, which can help you analyze search engine results pages and find the right keywords for your content.', 'Creating a community around your YouTube channel, as mentioned in fact 3, is also essential for keeping viewers engaged and coming back for more.', 'This can be achieved by responding to comments, running Q&A sessions, and engaging with your audience.', \"By doing so, you're building a relationship with your viewers and creating a sense of belonging to your community.\", 'This, in turn, can lead to increased engagement, loyalty, and even retention.']\n",
      " > Processing time: 124.69517278671265\n",
      " > Real-time factor: 0.8570892373362878\n",
      " > Text splitted to sentences.\n",
      "['Now, I know some of you might be thinking, \"But I\\'m not good at marketing or promoting myself.\"', \"Don't worry, it's okay.\", 'The key is to start small and be consistent.', 'Try promoting your channel on one or two social media platforms at first, and then gradually expand to more.', 'Remember, promoting your channel, not just your videos, can help increase your views and improve your return on investment (ROI), as mentioned in fact 4.', \"This means that instead of just sharing individual video links, you're sharing your channel link and encouraging viewers to subscribe and engage with your content.\", \"Finally, don't be afraid to experiment and try new things.\", 'Building a community and engaging with your audience, as mentioned in fact 5, is all about finding what works and doing more of it.', 'So, keep trying new strategies, keep listening to your audience, and keep promoting your channel.', \"By doing so, you'll be able to refine your approach, improve your engagement, and ultimately, achieve your YouTube goals.\"]\n",
      " > Processing time: 69.35601353645325\n",
      " > Real-time factor: 0.875077876649558\n",
      "Generated Audio Paths: ['../assets/audio\\\\slide1.wav', '../assets/audio\\\\slide2.wav', '../assets/audio\\\\slide3.wav', '../assets/audio\\\\slide4.wav', '../assets/audio\\\\slide5.wav', '../assets/audio\\\\slide6.wav', '../assets/audio\\\\slide7.wav', '../assets/audio\\\\slide8.wav', '../assets/audio\\\\slide9.wav', '../assets/audio\\\\slide10.wav', '../assets/audio\\\\slide11.wav', '../assets/audio\\\\slide12.wav', '../assets/audio\\\\slide13.wav', '../assets/audio\\\\slide14.wav']\n"

      "[ERROR] Failed to generate audio for slide 1: Error code: 400 - {'error': {'message': 'The model `playai-tts` requires terms acceptance. Please have the org admin accept the terms at https://console.groq.com/playground?model=playai-tts', 'type': 'invalid_request_error', 'code': 'model_terms_required'}}\n",
      "[ERROR] Failed to generate audio for slide 2: Error code: 400 - {'error': {'message': 'The model `playai-tts` requires terms acceptance. Please have the org admin accept the terms at https://console.groq.com/playground?model=playai-tts', 'type': 'invalid_request_error', 'code': 'model_terms_required'}}\n",
      "[ERROR] Failed to generate audio for slide 3: Error code: 400 - {'error': {'message': 'The model `playai-tts` requires terms acceptance. Please have the org admin accept the terms at https://console.groq.com/playground?model=playai-tts', 'type': 'invalid_request_error', 'code': 'model_terms_required'}}\n",
      "[ERROR] Failed to generate audio for slide 4: Error code: 400 - {'error': {'message': 'The model `playai-tts` requires terms acceptance. Please have the org admin accept the terms at https://console.groq.com/playground?model=playai-tts', 'type': 'invalid_request_error', 'code': 'model_terms_required'}}\n",
      "[ERROR] Failed to generate audio for slide 5: Error code: 400 - {'error': {'message': 'The model `playai-tts` requires terms acceptance. Please have the org admin accept the terms at https://console.groq.com/playground?model=playai-tts', 'type': 'invalid_request_error', 'code': 'model_terms_required'}}\n",
      "[ERROR] Failed to generate audio for slide 6: Error code: 400 - {'error': {'message': 'The model `playai-tts` requires terms acceptance. Please have the org admin accept the terms at https://console.groq.com/playground?model=playai-tts', 'type': 'invalid_request_error', 'code': 'model_terms_required'}}\n",
      "[ERROR] Failed to generate audio for slide 7: Error code: 400 - {'error': {'message': 'The model `playai-tts` requires terms acceptance. Please have the org admin accept the terms at https://console.groq.com/playground?model=playai-tts', 'type': 'invalid_request_error', 'code': 'model_terms_required'}}\n",
      "[ERROR] Failed to generate audio for slide 8: Error code: 400 - {'error': {'message': 'The model `playai-tts` requires terms acceptance. Please have the org admin accept the terms at https://console.groq.com/playground?model=playai-tts', 'type': 'invalid_request_error', 'code': 'model_terms_required'}}\n",
      "[ERROR] Failed to generate audio for slide 9: Error code: 400 - {'error': {'message': 'The model `playai-tts` requires terms acceptance. Please have the org admin accept the terms at https://console.groq.com/playground?model=playai-tts', 'type': 'invalid_request_error', 'code': 'model_terms_required'}}\n",
      "[ERROR] Failed to generate audio for slide 10: Error code: 400 - {'error': {'message': 'The model `playai-tts` requires terms acceptance. Please have the org admin accept the terms at https://console.groq.com/playground?model=playai-tts', 'type': 'invalid_request_error', 'code': 'model_terms_required'}}\n",
      "[ERROR] Failed to generate audio for slide 11: Error code: 400 - {'error': {'message': 'The model `playai-tts` requires terms acceptance. Please have the org admin accept the terms at https://console.groq.com/playground?model=playai-tts', 'type': 'invalid_request_error', 'code': 'model_terms_required'}}\n",
      "[ERROR] Failed to generate audio for slide 12: Error code: 400 - {'error': {'message': 'The model `playai-tts` requires terms acceptance. Please have the org admin accept the terms at https://console.groq.com/playground?model=playai-tts', 'type': 'invalid_request_error', 'code': 'model_terms_required'}}\n",
      "[ERROR] Failed to generate audio for slide 13: Error code: 400 - {'error': {'message': 'The model `playai-tts` requires terms acceptance. Please have the org admin accept the terms at https://console.groq.com/playground?model=playai-tts', 'type': 'invalid_request_error', 'code': 'model_terms_required'}}\n",
      "[ERROR] Failed to generate audio for slide 14: Error code: 400 - {'error': {'message': 'The model `playai-tts` requires terms acceptance. Please have the org admin accept the terms at https://console.groq.com/playground?model=playai-tts', 'type': 'invalid_request_error', 'code': 'model_terms_required'}}\n",
      "Generated Audio Paths: ['', '', '', '', '', '', '', '', '', '', '', '', '', '']\n"

     ]
    }
   ],
   "source": [
    "final_state = compiled_graph.invoke({})\n",
    "print(\"Generated Audio Paths:\", final_state['audio_output_path'])"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 13,
   "id": "cc319b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(final_state['ppt_output_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75679d9",

   "execution_count": null,
   "id": "cc319b0b",

   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
