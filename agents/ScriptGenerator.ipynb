{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b26160ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence, TypedDict, List, Dict\n",
    "from dotenv import load_dotenv  \n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage, SystemMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c467557",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]= GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b571ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "# llm.invoke(\"hello who are you\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad7a5bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    user_prompt: str                                 # Original user input prompt\n",
    "    scraped_data: List[Dict[str, str]]               # Raw web content scraped\n",
    "    subtopics: List[str]                             # List of 5–7 subtopics generated by LLM\n",
    "    full_script: List[Dict[str, str]]                                   # Full generated narration/script\n",
    "    slide_segments: List[Dict[str, str]]             # Segmented slide content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff7dd2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_subtopics(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Generate slide-worthy subtopics from a given user prompt.\n",
    "\n",
    "    This tool asks the LLM to break the provided topic into 3-4 concise \n",
    "    and informative subtopics suitable for video slides, without considering \n",
    "    any duration specified by the user.\n",
    "\n",
    "    Args:\n",
    "        user_prompt (str): The user's input prompt containing the topic.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: A list of concise subtopics suitable for video slides.\n",
    "    \"\"\"\n",
    "    prompt = state['user_prompt']\n",
    "    response = llm.invoke(f\"Given the topic: '{prompt}', generate ONLY 5-7 concise subtopic titles \"\n",
    "        \"as a numbered list (1. Title, 2. Title, ...). \"\n",
    "        \"Do NOT include any explanations, definitions, or extra details.\")\n",
    "    state['subtopics'] = [s.strip() for s in response.content.split(\"\\n\") if s.strip()]\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fdbbf1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "LANGSEARCH_API_KEY = os.getenv(\"LANGSEARCH_API_KEY\")\n",
    "LANGSEARCH_API_URL = \"https://api.langsearch.com/v1/web-search\"\n",
    "import requests\n",
    "\n",
    "\n",
    "def fetch_resources(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Fetch web resources for each subtopic using LangSearch API.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): The current agent state with subtopics.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: Updated state with scraped_data populated.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {LANGSEARCH_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    for topic in state[\"subtopics\"]:\n",
    "        payload = {\n",
    "            \"query\": topic,\n",
    "            \"freshness\": \"noLimit\",\n",
    "            \"summary\": True,\n",
    "            \"count\": 2\n",
    "        }\n",
    "\n",
    "        response = requests.post(LANGSEARCH_API_URL, headers=headers, json=payload)\n",
    "\n",
    "        topic_results = []\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            web_pages = data.get(\"data\", {}).get(\"webPages\", {}).get(\"value\", [])\n",
    "\n",
    "            for page in web_pages:\n",
    "                topic_results.append({\n",
    "                    \"title\": page.get(\"name\"),\n",
    "                    \"url\": page.get(\"url\"),\n",
    "                    \"summary\": page.get(\"summary\")\n",
    "                })\n",
    "\n",
    "        state[\"scraped_data\"].append({\n",
    "            \"topic\": topic,\n",
    "            \"results\": topic_results\n",
    "        })\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43586e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def create_script(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    For each subtopic, combine scraped content and generate:\n",
    "    - Key facts for slides.\n",
    "    - Narration script for presenters.\n",
    "\n",
    "    Updates:\n",
    "    - state[\"full_script\"]: List of dicts per subtopic with 'topic', 'narration', 'facts'.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): The agent state with scraped_data.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: Updated with structured full_script.\n",
    "    \"\"\"\n",
    "    state[\"full_script\"] = []\n",
    "\n",
    "    for data in state[\"scraped_data\"]:\n",
    "        topic = data.get(\"topic\", \"\")\n",
    "        results = data.get(\"results\", [])\n",
    "\n",
    "        combined_summary = \"\\n\".join(\n",
    "            result.get(\"summary\", \"\") for result in results if result.get(\"summary\", \"\")\n",
    "        )\n",
    "        if len(combined_summary) > 4000:\n",
    "            combined_summary = combined_summary[:4000]\n",
    "\n",
    "        if not combined_summary:\n",
    "            continue\n",
    "\n",
    "        llm_prompt = (\n",
    "            f\"Using the following information as context:\\n'''{combined_summary}'''\\n\\n\"\n",
    "            f\"Generate the following two outputs strictly in PLAIN TEXT (no HTML, no markdown, no special formatting). \"\n",
    "            f\"Use EXACTLY the headings 'Facts:' and 'Narration Script:' with no extra symbols or decoration.\\n\\n\"\n",
    "\n",
    "            f\"Facts:\\n\"\n",
    "            f\"List exactly 2 to 3 key facts about the topic '{topic}'. Format them as:\\n\"\n",
    "            f\"1. First fact\\n\"\n",
    "            f\"2. Second fact\\n\"\n",
    "            f\"3. Third fact (optional)\\n\"\n",
    "            f\"Do NOT use bullet points, dashes, asterisks, markdown symbols, or any formatting — ONLY numbered plain text facts.\\n\\n\"\n",
    "\n",
    "            f\"Narration Script:\\n\"\n",
    "            f\"Write a complete, engaging YouTube video narration script for the topic '{topic}'. \"\n",
    "            f\"The narration MUST explain the facts listed above in a natural, conversational, and friendly tone, \"\n",
    "            f\"as if the presenter is talking directly to the audience. \"\n",
    "            f\"Do NOT include any stage directions, sound effects, descriptions of background music, presenter actions, or visual cues. \"\n",
    "            f\"Ensure this is strictly plain text with no HTML, markdown, or any other formatting.\\n\"\n",
    "        )\n",
    "\n",
    "\n",
    "        response = llm.invoke(llm_prompt)\n",
    "        output = response.content.strip()\n",
    "\n",
    "        # Split based on the \"2. Narration Script\" section, case-insensitive\n",
    "        split_match = re.split(r\"\\bNarration Script:\\s*\", output, maxsplit=1, flags=re.IGNORECASE)\n",
    "        facts_part = split_match[0].replace(\"Facts:\", \"\").strip()\n",
    "        narration_part = split_match[1].strip() if len(split_match) > 1 else \"\"\n",
    "\n",
    "\n",
    "        state[\"full_script\"].append({\n",
    "            \"topic\": topic,\n",
    "            \"facts\": facts_part,\n",
    "            \"narration\": narration_part\n",
    "        })\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33ef8eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "\n",
    "def create_slide_segments(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Generates structured slide segments for each subtopic based on narration and facts.\n",
    "    \n",
    "    For each slide:\n",
    "    - content_to_display: Contains the specific facts relevant to that slide.\n",
    "    - narration_script: Explains the facts shown in content_to_display.\n",
    "    - is_blank_slide: True if the slide is meant to show stock video only.\n",
    "    \"\"\"\n",
    "    state[\"slide_segments\"] = []\n",
    "    slide_counter = 1\n",
    "\n",
    "    for script_data in state[\"full_script\"]:\n",
    "        subtopic = script_data[\"topic\"]\n",
    "        narration = script_data[\"narration\"]\n",
    "        facts = script_data[\"facts\"]\n",
    "\n",
    "        llm_prompt = (\n",
    "            f\"For the subtopic '{subtopic}', you are provided with:\\n\\n\"\n",
    "            f\"Facts:\\n{facts}\\n\\n\"\n",
    "            f\"Narration Script:\\n{narration}\\n\\n\"\n",
    "            f\"Your task is to divide this content into up to 2 slides. For each slide:\\n\"\n",
    "            f\"- In 'Display', ONLY show the relevant facts for that slide.\\n\"\n",
    "            f\"- In 'Narration', provide the portion of the narration that directly explains the displayed facts and explain the facts in great detail.\\n\"\n",
    "            f\"- If there's a narration section that doesn't require any fact display (like general commentary), mark that slide's display as 'BLANK_SLIDE'.\\n\\n\"\n",
    "            f\"STRICT RULES:\\n\"\n",
    "            f\"- Maximum of 2 slides per subtopic.\\n\"\n",
    "            f\"- Only split into 2 if necessary.\\n\"\n",
    "            f\"- Always pair facts with their explanations.\\n\\n\"\n",
    "            f\"Format your output strictly as:\\n\"\n",
    "            f\"Slide 1:\\nDisplay: <Facts or BLANK_SLIDE>\\nNarration: <Narration for this slide>\\n\\n\"\n",
    "            f\"Slide 2:\\nDisplay: <Facts or BLANK_SLIDE>\\nNarration: <Narration for this slide>\\n\\n\"\n",
    "            f\"Ensure clarity and direct fact-to-narration mapping.\"\n",
    "        )\n",
    "\n",
    "        response = llm.invoke(llm_prompt)\n",
    "        slides_text = response.content.strip()\n",
    "\n",
    "        # Parse LLM response into slides\n",
    "        slide_matches = re.split(r'Slide \\d+:', slides_text)\n",
    "        for slide_data in slide_matches:\n",
    "            if not slide_data.strip():\n",
    "                continue\n",
    "\n",
    "            display_match = re.search(r'Display:\\s*(.*?)\\nNarration:', slide_data, re.DOTALL)\n",
    "            narration_match = re.search(r'Narration:\\s*(.*)', slide_data, re.DOTALL)\n",
    "\n",
    "            content_to_display = display_match.group(1).strip() if display_match else \"\"\n",
    "            narration_text = narration_match.group(1).strip() if narration_match else \"\"\n",
    "\n",
    "            is_blank_slide = content_to_display.strip().upper() == \"BLANK_SLIDE\"\n",
    "\n",
    "            state[\"slide_segments\"].append({\n",
    "                \"slide_no\": slide_counter,\n",
    "                \"subtopic\": subtopic,\n",
    "                \"content_to_display\": content_to_display,\n",
    "                \"narration_script\": narration_text,\n",
    "                \"is_blank_slide\": is_blank_slide,\n",
    "                \"image_address\" : \"\",\n",
    "                \"video_address\" : \"\",\n",
    "                \"image_position\"  :\"\",\n",
    "                \"test_position\": \"\"\n",
    "            })\n",
    "\n",
    "            slide_counter += 1\n",
    "\n",
    "    # Save subtopics and slide_segments to JSON\n",
    "    output_dir = \"../assets/scripts\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(output_dir, \"slide_segments.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\n",
    "            \"subtopics\": state.get(\"subtopics\", []),\n",
    "            \"slide_segments\": state[\"slide_segments\"]\n",
    "        }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e776c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2988c478e50>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "graph_builder.add_node(\"Generate_Subtopics\", generate_subtopics)\n",
    "graph_builder.add_node(\"Fetch_Resources\", fetch_resources)\n",
    "graph_builder.add_node(\"Create_Script\", create_script)\n",
    "graph_builder.add_node(\"Create_Slide_Segments\", create_slide_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c4f74bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(START, \"Generate_Subtopics\")\n",
    "graph_builder.add_edge(\"Generate_Subtopics\", \"Fetch_Resources\")\n",
    "graph_builder.add_edge(\"Fetch_Resources\", \"Create_Script\")\n",
    "graph_builder.add_edge(\"Create_Script\", \"Create_Slide_Segments\")\n",
    "graph_builder.add_edge(\"Create_Slide_Segments\", END)\n",
    "\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e985e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = input(\"Enter your topic prompt: \")\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [],\n",
    "    \"user_prompt\": user_prompt,\n",
    "    \"scraped_data\": [],\n",
    "    \"subtopics\": [],\n",
    "    \"full_script\": [],\n",
    "    \"slide_segments\": []\n",
    "}\n",
    "\n",
    "final_state = graph.invoke(initial_state)\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"\\n--- Subtopics ---\")\n",
    "pprint(final_state[\"subtopics\"])\n",
    "\n",
    "print(\"\\n--- Full Script ---\")\n",
    "pprint(final_state[\"full_script\"])\n",
    "\n",
    "print(\"\\n--- Slide Segments ---\")\n",
    "pprint(final_state[\"slide_segments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0338c4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
